# 多级缓存



## 什么是多级缓存

> 传统的缓存架构的请求流程: 一个请求首先到达我们的服务器(Tomcat),随后去查询Redis缓存,缓存没有再去数据库中查。

存在以下问题:

- 所有请求都会到达服务器(Tomcat),Tomcat成为整个服务的性能瓶颈
- 当Redis缓存失效,会对数据库造成冲击

多级缓存的目的就是充分拆分整个请求流程中的所有环节,在整个请求流程添加多级缓存,减轻服务器压力

- 对于静态资源,浏览器会优先读取本地缓存
- 对于非静态资源,访问服务器
  - 在Ngnix添加缓存,请求到达Nginx,优先读取Ngnix本地缓存
  - Ngnix本地缓存未命中,则请求Redis
  - Redis没命中,则请求服务器(Tomcat)
  - 请求进入Tomcat,优先查询JVM本地进程缓存
  - JVM本地进程缓存未命中则查询数据库

![image-20210821075558137](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20210821075558137.png)

> 在多级缓存的架构中,Nginx不再只作为一个静态资源的提供者,而是成为了一个提供业务逻辑的`Web服务器`
>
> Nginx存在以下职责：
>
> - 反向代理
> - 负载均衡
> - 本地缓存
> - Redis查询
> - Tomcat查询(请求反向代理到服务器Tomcat)

正是因为Nginx负责的职责较多,所以Ngnix也需要搭建集群：

![image-20210821080511581](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20210821080511581.png)

同时Tomcat也会集群部署：

![image-20210821080954947](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20210821080954947.png)



> 在多级缓存架构中需要解决的点是:

- 在Ngnix编写业务逻辑
  - Nngix本地缓存
  - 查询Redis
  - 查询Tomcat
- JVM本地进程缓存

其中Nginx编程则会用到OpenResty框架结合Lua这样的语言。

## 例子

> 商品查询例子

#### docker安装Mysql

使用docker安装Mysql

##### 1.1、安装docker

> 执行`docker -v`查看提示即可

[安装docker](https://yeasy.gitbook.io/docker_practice/install/ubuntu)

```snap install docker```

安装成功查看docker版本：

```shell
root@ubuntu-linux-22-04-desktop:/home/tmp/docker/mysql# docker -v
Docker version 20.10.17, build 100c70180f
```

##### 1.2、准备挂载目录

挂载路径：`/home/tmp/docker/mysql`

##### 1.3、启动容器

1.2.1、拉取Mysql镜像

```shell
## 查看docker帮助
docker --help

## 搜索mysql镜像
docker search mysql

## 拉取docker 镜像。下载成功后会有Status: Downloaded newer image for mysql:latest提示
docker pull mysql:latest
```

1.2.2、启动mysql并挂载目录

```shell
docker run \
 -p 3306:3306 \
 --name mysql \
 -v $PWD/conf:/etc/mysql/conf.d \
 -v $PWD/logs:/logs \
 -v $PWD/data:/var/lib/mysql \
 -e MYSQL_ROOT_PASSWORD=123456 \
 --privileged \
 -d \
 mysql:latest
```

参数说明：

- `-p`端口映射
- `--name` docker容器名称
- `-v`参数这里是,挂载目录。格式为`本地路径:容器内部路径`
- `-e` envirment,设置环境变量
- `--privileged`使得mysql拥有root权限
- `-d`后台启动

启动状态：

![image-20230420035338261](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230420035338261.png)

> 交互模式进入docker-mysql容器并使用mysql客户端连接mysql

```shell
# 交互模式进入docker容器
docker exec -it dfc3cedea039 /bin/bash
# 连接mysql 
mysql -u root -p
mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| sys                |
+--------------------+
4 rows in set (0.00 sec)
```

> Mysql可视化客户端Navicat远程连接mysql

![image-20230420042029050](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230420042029050.png)

##### 1.4、修改配置

> 交互模式进入docker-mysql容器,是缺省mysql配置文件的,我们需要本地创建并挂载上去。

![image-20230420042442494](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230420042442494.png)

1.4.1、在`$pwd/mysql/conf`下创建`my.cnf`文件

```ini
[mysqld]
## 跳过ip解析域名过程,提高查询效率
skip-name-resolve
character_set_server=utf8
## mysqldata目录
datadir=/var/lib/mysql
## 唯一id
server-id=1000
## MySQL 客户端连接服务器端时使用的端口号，默认为 3306
port=3306
## mysqld_safe 脚本将默认使用 user=mysql 选项来启动
user = mysql
```

1.4.2、重启

`docker restart mysql`



#### 初始化数据

```sql
SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;
create DATABASE if not EXISTS `item`;
use `item`;
DROP TABLE IF EXISTS `tb_item`;
CREATE TABLE `tb_item`  (
  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '商品id',
  `title` varchar(264) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '商品标题',
  `name` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '商品名称',
  `price` bigint(20) NOT NULL COMMENT '价格（分）',
  `image` varchar(200) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '商品图片',
  `category` varchar(200) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '类目名称',
  `brand` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '品牌名称',
  `spec` varchar(200) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '规格',
  `status` int(1) NULL DEFAULT 1 COMMENT '商品状态 1-正常，2-下架，3-删除',
  `create_time` datetime NULL DEFAULT NULL COMMENT '创建时间',
  `update_time` datetime NULL DEFAULT NULL COMMENT '更新时间',
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `status`(`status`) USING BTREE,
  INDEX `updated`(`update_time`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 10001 CHARACTER SET = utf8mb4 COMMENT = '商品表' ROW_FORMAT = COMPACT;

INSERT INTO `tb_item`(`title` ,`name` ,`price` ,`image` ,`category` ,`brand`,`spec` ,`status` ,`create_time` ,`update_time` )
 VALUES ('RIMOWA 21寸托运箱拉杆箱 SALSA AIR系列果绿色 820.70.36.4', 'SALSA AIR', 16900, 'https://m.360buyimg.com/mobilecms/s720x720_jfs/t6934/364/1195375010/84676/e9f2c55f/597ece38N0ddcbc77.jpg!q70.jpg.webp', '拉杆箱', 'RIMOWA', '{\"颜色\": \"红色\", \"尺码\": \"26寸\"}', 1, '2019-05-01 00:00:00', '2019-05-01 00:00:00')
 , ('安佳脱脂牛奶 新西兰进口轻欣脱脂250ml*24整箱装*2', '脱脂牛奶', 68600, 'https://m.360buyimg.com/mobilecms/s720x720_jfs/t25552/261/1180671662/383855/33da8faa/5b8cf792Neda8550c.jpg!q70.jpg.webp', '牛奶', '安佳', '{\"数量\": 24}', 1, '2019-05-01 00:00:00', '2019-05-01 00:00:00')
 , ('唐狮新品牛仔裤女学生韩版宽松裤子 A款/中牛仔蓝（无绒款） 26', '韩版牛仔裤', 84600, 'https://m.360buyimg.com/mobilecms/s720x720_jfs/t26989/116/124520860/644643/173643ea/5b860864N6bfd95db.jpg!q70.jpg.webp', '牛仔裤', '唐狮', '{\"颜色\": \"蓝色\", \"尺码\": \"26\"}', 1, '2019-05-01 00:00:00', '2019-05-01 00:00:00')
 , ('森马(senma)休闲鞋女2019春季新款韩版系带板鞋学生百搭平底女鞋 黄色 36', '休闲板鞋', 10400, 'https://m.360buyimg.com/mobilecms/s720x720_jfs/t1/29976/8/2947/65074/5c22dad6Ef54f0505/0b5fe8c5d9bf6c47.jpg!q70.jpg.webp', '休闲鞋', '森马', '{\"颜色\": \"白色\", \"尺码\": \"36\"}', 1, '2019-05-01 00:00:00', '2019-05-01 00:00:00')
 , ('花王（Merries）拉拉裤 M58片 中号尿不湿（6-11kg）（日本原装进口）', '拉拉裤', 38900, 'https://m.360buyimg.com/mobilecms/s720x720_jfs/t24370/119/1282321183/267273/b4be9a80/5b595759N7d92f931.jpg!q70.jpg.webp', '拉拉裤', '花王', '{\"型号\": \"XL\"}', 1, '2019-05-01 00:00:00', '2019-05-01 00:00:00');
DROP TABLE IF EXISTS `tb_item_stock`;
CREATE TABLE `tb_item_stock`  (
  `item_id` bigint(20) NOT NULL COMMENT '商品id，关联tb_item表',
  `stock` int(10) NOT NULL DEFAULT 9999 COMMENT '商品库存',
  `sold` int(10) NOT NULL DEFAULT 0 COMMENT '商品销量',
  PRIMARY KEY (`item_id`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci COMMENT = '库存表' ROW_FORMAT = COMPACT;
INSERT INTO `tb_item_stock` VALUES (10001, 99996, 3219);
INSERT INTO `tb_item_stock` VALUES (10002, 99999, 54981);
INSERT INTO `tb_item_stock` VALUES (10003, 99999, 189);
INSERT INTO `tb_item_stock` VALUES (10004, 99999, 974);
INSERT INTO `tb_item_stock` VALUES (10005, 99999, 18649);
SET FOREIGN_KEY_CHECKS = 1;
```

#### 导入后端项目



#### 导入前端项目

> docker安装nginx

1. docker  search nginx

2. docker pull nginx

3. docker run --name nginx -d nginx:latest

4. 复制目录

   ```shell
   docker cp nginx:/etc/nginx ./conf
   docker cp nginx:/var/log/nginx ./logs
   docker cp nginx:/var/run/nginx.pid ./logs/nginx.pid
   docker cp nginx:/usr/share/nginx/html ./html
   ```

5. 拷贝前端项目到html

6. 修改配置

   > 所有请求到`10.211.55.4：80`的请求都会被代理到`upstream nginx-cluster`这个后期也会配成集群作为nginx业务集群

   ```nginx
   
   #user  nobody;
   worker_processes  1;
   
   events {
       worker_connections  1024;
   }
   
   http {
       include       mime.types;
       default_type  application/octet-stream;
   
       sendfile        on;
       #tcp_nopush     on;
       keepalive_timeout  65;
   
       upstream nginx-cluster{
           # 这个是我又开了个虚拟机 分配的ip为10.211.55.5
           server 10.211.55.5:8081;
       }
       server {
           listen       80;
           server_name  localhost;
   
           location /api {
               proxy_pass http://nginx-cluster;
           }
   
           location / {
               root   /usr/share/nginx/html;
               index  index.html index.htm;
           }
   
           error_page   500 502 503 504  /50x.html;
           location = /50x.html {
               root   html;
           }
       }
   }

访问:

`http://10.211.55.4/item.html?id=10001`

![image-20230421123154493](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230421123154493.png)



## JVM进程缓存

> 即将数据保存在JVM内存中,请求时首先查询缓存,未命中再去查询数据库。



### Caffeine

缓存在日常开发中启动至关重要的作用，由于是存储在内存中，数据的读取速度是非常快的，能大量减少对数据库的访问，减少数据库的压力。我们把缓存分为两类：

- 分布式缓存，例如Redis：
  - 优点：存储容量更大、可靠性更好、可以在集群间共享
  - 缺点：访问缓存有网络开销
  - 场景：缓存数据量较大、可靠性要求较高、需要在集群间共享
- 进程本地缓存，例如HashMap、GuavaCache：
  - 优点：读取本地内存，没有网络开销，速度更快
  - 缺点：存储容量有限、可靠性较低、无法共享
  - 场景：性能要求较高，缓存数据量较小

我们今天会利用Caffeine框架来实现JVM进程缓存。



**Caffeine**是一个基于Java8开发的，提供了近乎最佳命中率的高性能的本地缓存库。目前Spring内部的缓存使用的就是Caffeine。GitHub地址：https://github.com/ben-manes/caffeine

Caffeine的性能非常好，下图是官方给出的性能对比(读 (75%) / 写 (25%))：

![img](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/readwrite.png)

#### 基本使用

```java
@Test
void testBasicOps() {
    // 创建缓存对象
    Cache<String, String> cache = Caffeine.newBuilder().build();
    // 存数据
    cache.put("gf", "迪丽热巴");

    // 取数据，不存在则返回null
    String gf = cache.getIfPresent("gf");
    System.out.println("gf = " + gf);

    // 取数据，不存在则去数据库查询
    String defaultGF = cache.get("defaultGF", key ->
            // 这里可以去数据库根据 key查询value
            "柳岩"
    );
    System.out.println("defaultGF = " + defaultGF);
}
```



#### Caffeine驱逐策略

Caffeine提供了三种缓存驱逐策略：

- **基于容量**：设置缓存的数量上限

  ```java
  // 创建缓存对象
  Cache<String, String> cache = Caffeine.newBuilder()
      .maximumSize(1) // 设置缓存大小上限为 1
      .build();
  ```

- **基于时间**：设置缓存的有效时间

  ```java
  // 创建缓存对象
  Cache<String, String> cache = Caffeine.newBuilder()
      // 设置缓存有效期为 10 秒，从最后一次写入开始计时 
      .expireAfterWrite(Duration.ofSeconds(10)) 
      .build();
  
  ```

- **基于引用**：设置缓存为软引用或弱引用，利用GC来回收缓存数据。性能较差，不建议使用。

> **注意**：在默认情况下，当一个缓存元素过期的时候，Caffeine不会自动立即将其清理和驱逐。而是在一次读或写操作后，或者在空闲时间完成对失效数据的驱逐。

### 实现JVM进程缓存

#### 需求

利用Caffeine实现下列需求：

- 给根据id查询商品的业务添加缓存，缓存未命中时查询数据库
- 给根据id查询商品库存的业务添加缓存，缓存未命中时查询数据库
- 缓存初始大小为100
- 缓存上限为10000

#### 实现

##### 注入Cache

```java
@Bean
public Cache<Long, Item> itemCache() {
    return Caffeine.newBuilder()
            .initialCapacity(100)
            .maximumSize(10_000)
            .build();
}

@Bean
public Cache<Long, ItemStock> itemStockCache() {
    return Caffeine.newBuilder()
            .initialCapacity(100)
            .maximumSize(10_000)
            .build();
}
```

##### 修改查询业务逻辑

> `@Autowrite`注解默认按照类型注入,如果按照类型注入失败的话,则会根据属性名称Byname的方式注入。

```java
@Autowired
Cache<Long, Item> itemCache;

@Autowired
@Qualifier("itemStockCache")//可以省略
Cache<Long, ItemStock> itemStockCache;

@GetMapping("/{id}")
public Item findById(@PathVariable("id") Long id) {
    return itemCache.get(
            id,
            key -> itemService.query().ne("status", 3).eq("id", key).one()
    );
}
@GetMapping("/stock/{id}")
public ItemStock findStockById(@PathVariable("id") Long id) {
    return itemStockCache.get(id, key -> stockService.getById(key));
}
```



## Ngnix缓存

> Ngnix除了存储静态资源和做反向代理,还可以使用`Lua`编写业务逻辑。

### Lua

Lua是一种强大而快速的编程语言 它易于学习和使用，并易于嵌入到应用程序中。Lua被设计成一种轻量级的可嵌入脚本语言,从而为应用程序提供灵活的扩展和定制功能。

[Lua官网](https://www.lua.org/)

#### HelloWorld

1. 安装lua

   命令行输入`Lua`根据提示安装即可

![image-20230420064432658](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230420064432658.png)

2. 创建`hello.lua`

   > 并输入`print('Hello World!')`

   ```shell
   vim hello.lua
   ```

3. 执行`hello.lua`

   ```lua
   lua hello.lua
   ```

   ![image-20230420065011378](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230420065011378.png)

​	

#### 基本语法

> Lua基本语法学习。

##### Lua数据类型

> Lua是一种动态类型语言,变量没有类型,只有价值观 
>
> Lua中有八种基本类型： nil，boolean，number， 字符串、函数、用户数据 线程和表。

![image-20210821091835406](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20210821091835406.png)

> 变量声明

```lua
-- hello world
print('Hellow World!!')

-- type()函数可以判断一个变量的类型
print(type('Hello Lua'))
print(type(function() return 1 end))
 
-- 声明局部变量 local

-- 声明字符串
local str = 'hello'
-- 字符串拼接用 ..
local appned = str .. 'lua'
print(append)
-- 声明数字
local age = 23
-- 声明boolean
local flag = true

-- 声明table类型
-- 数组(也作为map,key为角标)
local arr = {'java','lua','python'}
-- map
local map = {name='yuyc',age=22}
```

> table使用

作为数组使用下标从1开始

```lua
-- table的下标从1开始
print(arr[1])
```

table作为map既可以以数组访问也可以以.访问

```lua
-- table作为map既可以以数组访问也可以以.访问
print(map[name])
print(map.name)
```

##### lua循环

```lua
-- lua循环
for index, value in ipairs(arr) do
    print(index, value)
end
for key, value in pairs(map) do
    print(key, value)
end
```

##### 条件控制

```lua
-- lua 条件控制
local num = 100;
if num > 10 then
    print(num)
else
    print(num)
end
```

##### 函数

函数定义

```lua
function 函数名( argument1, argument2..., argumentn)
    -- 函数体
    return 返回值
end
```

```lua
-- lua 函数
function pairsArr(arr)
    if not arr then
        return nil;
    end
    for index, value in ipairs(arr) do
        print(value)
    end
    return arr
end
print(pairsArr(arr))
```



### 实现Ngnix缓存

多级缓存的实现离不开Nginx编程，而Nginx编程又离不开OpenResty。

#### OpenRestry

##### 简介

> OpenResty是一个成熟的Web平台,它旨在帮助开发人员轻松 构建可伸缩的Web应用程序、Web服务和动态Web网关。可以直接作为一个Nginx使用
>
> 它集成了: 
>
> - 增强版本 Nginx核心
> - 增强版 LuaJIT
> - 许多Lua库
> - 很多高质量的 第三方Nginx模块
> -  大部分的外部依赖

[OpenResty官网](https://openresty.org/cn/)

##### 安装

[OpenResty安装](https://openresty.org/cn/linux-packages.html)

我使用的Linux发行版本为`Fedora 36`

###### 安装开发库

> 根据不同Linux发行版选择安装方式

[地址](https://openresty.org/cn/installation.html)

```shell
yum install -y pcre-devel openssl-devel gcc --skip-broken
```

###### 安装yun-utils

```shel
yum install -y yum-utils
```

###### 安装openrestry仓库

> 根据不同版本选择安装方式

[openrestry地址](https://openresty.org/cn/linux-packages.html)

```shell
sudo dnf install -y dnf-plugins-core

sudo dnf config-manager --add-repo https://openresty.org/package/fedora/openresty.repo
```

> 安装Openrestry

```shell
sudo dnf install -y openresty
```

###### 安装工具

```shell
sudo dnf install -y openresty-opm
```

###### openresty默认安装路径

![image-20230420093158627](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230420093158627.png)

###### 配置环境变量

1. 打开配置文件

   ```shell
   vi /etc/profile
   ```

2. 添加环境变量

   ```shell
   export NGINX_HOME=/usr/local/openresty/nginx
   export PATH=${NGINX_HOME}/sbin:$PATH
   ```

3. 生效配置

   ```shell
   source /etc/profile
   ```

###### 启动

```shell
# 启动nginx
nginx
# 重新加载配置
nginx -s reload
# 停止
nginx -s stop
```



###### 配置

备份nginx默认配置

```shell
cp nginx.conf nginx.conf.backup
rm ngnix.conf
```

`vim nginx.conf`添加如下配置

```properties
#user  nobody;
worker_processes  1;
error_log  logs/error.log;

events {
    worker_connections  1024;
}

http {
    include       mime.types;
    default_type  application/octet-stream;
    sendfile        on;
    keepalive_timeout  65;

    server {
        listen       8081;
        server_name  localhost;
        location / {
            root   html;
            index  index.html index.htm;
        }
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
    }
}
```

启动并访问：

![image-20230420100639678](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230420100639678.png)

###### 添加OpenResty模块

> 在`nginx.conf`配置文件中添加Lua和c模块

```nginx
lua_package_path "/usr/local/openresty/lualib/?.lua;;";
lua_package_cpath "/usr/local/openresty/lualib/?.so;;";  
```

##### openresty入门

> Openresty是一个基于nginx和lua的高性能的Web平台,其内部集成了大量精良的Lua脚本库以及第三方模块。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。
>
> Openresty可以认为是一个增强的Nginx,不仅仅是静态的提供者,也可进行业务处理。

Openrestry在三层缓存架构中担任的角色是下图绿色框部分：

![image-20230421143733482](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230421143733482.png)

##### Openrestry监听请求

1. 在配置文件中添加Lua模块

```nginx
#lua 模块
lua_package_path "/usr/local/openresty/lualib/?.lua;;";
#c模块     
lua_package_cpath "/usr/local/openresty/lualib/?.so;;";  
```

2. 监听请求

   > 在`nginx.conf`文件中配置需要拦截的请求

​	![image-20230421144607059](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230421144607059.png)

3. 编写处理程序`lua/item.lua`

   ```lua
   ngx.say('{"id":10001,"name":"SALSA AIR","title":"RIMOWA 21寸托运箱拉杆箱 SALSA AIR系列果绿色 820.70.36.4","price":17900,"image":"https://m.360buyimg.com/mobilecms/s720x720_jfs/t6934/364/1195375010/84676/e9f2c55f/597ece38N0ddcbc77.jpg!q70.jpg.webp","category":"拉杆箱","brand":"RIMOWA","spec":"","status":1,"createTime":"2019-04-30T16:00:00.000+00:00","updateTime":"2019-04-30T16:00:00.000+00:00","stock":2999,"sold":31290}')
   ```

​		![image-20230421145200003](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230421145200003.png)

4. 重新加载nginx配置

   ```shell
   nginx -s reload
   ```

5. 测试

   > 修改价格为119,测试数据的动态性
   >
   > 访问地址：`http://10.211.55.4/item.html?id=10001`

   ![image-20230421150817118](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230421150817118.png)

##### Openrestry处理请求参数

> Openrestry可以拦截请求并返回动态数据,已经有业务能力了。
>
> Openrestry如何处理请求参数

###### Lua脚本获取请求参数api

> 请求参数可以在请求头、请求体、也可以是restful风格的。请求可以是get请求也可是post请求。根据不同的请求方式和请求参数存在的位置,Lua提供了对应api：

![image-20230421151331188](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230421151331188.png)

###### 处理请求参数

> 在`item.lua`中获取请求参数并返回。首先前端发来的请求是:`http://10.211.55.4/api/item/10001`第一个nginx服务器直接做反向代理,将请求代理给到Openrestry处理。
>
> 这是一个Restful风格的请求,需要使用正则表达式匹配,并将匹配到的请求参数放入`var`数组中。

1. 开启正则匹配

   ```nginx
   location ~ /api/item/(\d+) {
       # 默认的响应类型
       default_type application/json;
       # 响应结果由lua/item.lua文件来决定
       content_by_lua_file lua/item.lua;
   }
   ```

2. 获取参数

   > 正则表达式匹配到的参数会存入var这个table(数组)内。

   ![image-20230421152314487](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230421152314487.png)

3. 重载openrestry配置

   > 重载后测试。
   >
   > 数据也可以正常返回

   ```shell
   nginx -s reload
   ```

   ![image-20230421152533954](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230421152533954.png)

##### 请求Tomcat

> Openrestry可做缓存,那么缓存的数据哪里来？缓存数据是请求Tomcat返回的。这里实现Openrestry请求Tomcat并处理返回结果。

###### 发送Http请求

Nginx内部提供的发送Http请求的api：

```lua
local resp = ngx.location.capture("/item",{
    method = ngx.HTTP_GET,   -- 请求方式
    args = {id=1},  -- get方式传参数
})
```

返回的响应内容包括：

- resp.status：响应状态码
- resp.header：响应头，是一个table
- resp.body：响应体，就是响应数据

注意：这里的`/item`是路径，并不包含IP和端口。这个请求会被nginx内部的server监听并处理。

但是我们希望这个请求发送到Tomcat服务器，所以还需要编写一个server来对这个路径做反向代理

```nginx
 location /path {
     # 将请求代理给到Tomcat,即本地启动的java服务
     proxy_pass http://10.211.55.2:8081; 
 }
```

如果请求可以正常代理,那么前端发送的`http://10.211.55.4/item.html?id=10001`请求会被代理成`http://10.211.55.2:8081/id=10001`

> 写代码：

`item.lua`:

```lua
-- 拿到id
local id = ngx.var[1]
-- 以restful风格请求
local resp = ngx.location.capture("/item" .. "/" .. id ,{
        method = ngx.HTTP_GET,
        args = nil,
    })
if not resp then
     -- 记录错误信息，返回404
     ngx.log(ngx.ERR, "http请求查询失败, path: ", path , ", args: ", args)
     ngx.exit(404)
end
-- 返回响应体数据
ngx.say(resp.body)
```

`nginx.conf`：配置反向代理

```nginx
location /item {
    proxy_pass http://10.211.55.2:8081;
}
```

地址可以先`curl`测一下：

![image-20230421174611787](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230421174611787.png)

> 测试：

![image-20230421174705745](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230421174705745.png)

###### 封装http请求

在`nginx.conf`中我们引入了Lua模块:

![image-20230421174800173](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230421174800173.png)

就在这下面添加http请求工具：

```shell
[root@fedora lualib]# pwd
/usr/local/openresty/lualib

[root@fedora lualib]# vi common.lua
```

```lua
-- 封装函数，发送http请求，并解析响应
local function read_http(path, params)
    local resp = ngx.location.capture(path,{
        method = ngx.HTTP_GET,
        args = params,
    })
    if not resp then
        -- 记录错误信息，返回404
        ngx.log(ngx.ERR, "http请求查询失败, path: ", path , ", args: ", args)
        ngx.exit(404)
    end
    return resp.body
end
-- 将方法导出
local _M = {
    read_http = read_http
}
return _M            
```

> 使用封装的http请求工具

```lua
-- 引入自定义common工具模块，返回值是common中返回的 _M
local common = require("common")
-- 从 common中获取read_http这个函数
local read_http = common.read_http
-- 获取路径参数
local id = ngx.var[1]
-- 根据id查询商品
local itemJSON = read_http("/item/".. id, nil)
-- 根据id查询商品库存
local itemStockJSON = read_http("/item/stock/".. id, nil)

ngx.say(itemJSON)         
```



###### CJSON工具

> 上面发送了两个请求,获得了商品信息JSON和库存JSON,如何将JSON拼接成一个返回？
>
> 使用OpenResty提供的cjson模块用来处理JSON的序列化和反序列化。

1. 引入cjson

   > cjson在`openrestry/lualib`下可以直接引用

   ```lua
   local cjson = require("cjson")
   ```

2. 使用

   ```lua
   -- 引入自定义common工具模块，返回值是common中返回的 _M
   local common = require("common")
   -- 引入cjson
   local cjson = require("cjson")
   -- 从 common中获取read_http这个函数
   local read_http = common.read_http
   -- 获取路径参数
   local id = ngx.var[1]
   -- 根据id查询商品
   local itemJSON = read_http("/item/".. id, nil)
   -- 根据id查询商品库存
   local itemStockJSON = read_http("/item/stock/".. id, nil)
   -- 反序列化成 table
   local item = cjson.decode(itemJSON)
   local stock = cjson.decode(itemStockJSON)
   -- 反序列化成 table 可以通过item.stock或item.[stock]访问
   item.stock = stock.stock
   item.sold = stock.sold
   -- 序列化成json
   ngx.say(cjson.encode(item))                             
   ```

##### 负载均衡

> Openrestry可以请求到Tomcat了,而Tomcat定是集群部署的,因此Openrestry需要配置负载均衡策略,充分利用资源。

![image-20210821111023255](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20210821111023255.png)

>  默认负载均衡的配置为轮询

此负载均衡策略存在问题：查询同一个商品10001

第一次访问8081,8081查数据库,并缓存在Caffine中、第二次访问8082,8082查数据库,并缓存在Caffine中.....

- 浪费JVM内存
- 缓存命中率低

> 因此通过商品ID特征决定均衡策略 ： 得到请求路径哈希值,并除以机器数量取余

实现：修改`nginx.conf`配置

![image-20230421182222211](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230421182222211.png)

###### 测试

> idea模拟集群。

![image-20230421182700420](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230421182700420.png)

重命名分个组,启动即可

![image-20230421182753123](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230421182753123.png)

1、3、4在8082,2、5在8081

![image-20230421183102204](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230421183102204.png)

##### Redis缓存预热

> Redis会面临冷启动的问题,首次查询会给数据库带来压力

冷启动：服务刚启动,Redis中没有任何数据,所有数据在首次查询初始化。

缓存预热：对于热点数据可以在启动服务时将数据提前存到Redis中

###### docker安装Redis

1. 拉取镜像

   ```shell
   docker pull redis
   ```

2. 配置

   > 官网复制模板,修改以下配置即可

   ```properties
   # bind 127.0.0.1 -::1   ## 这个配置注掉,表示只允许本机连接。或修改为 bind 0.0.0.0
   daemonize no
   requirepass 123123 ## 设置密码
   ```

3. 启动redis

   ```shell
   docker run -d --privileged=true -p 6380:6379 \
   -v $PWD/conf/redis.conf:/etc/redis/redis.conf \
   -v $PWD/data:/data \
   --name redis redis redis-server /etc/redis/redis.conf \
   --appendonly yes 
   ```



###### 数据预热

1. 引入依赖

   ```xml
   <dependency>
       <groupId>org.springframework.boot</groupId>
       <artifactId>spring-boot-starter-data-redis</artifactId>
   </dependency>
   ```

2. 配置

   ```yml
   spring:
     redis:
       host: 10.211.55.4
       port: 6380
       password: 123123
       lettuce:
         pool:
           max-active: 10
           max-idle: 10
           min-idle: 1
           time-between-eviction-runs: 10s
   ```

3. 数据预热

   > 缓存预热需要在项目启动时完成，并且必须是拿到RedisTemplate之后。
   >
   > 这里我们利用InitializingBean接口来实现，因为InitializingBean可以在对象被Spring创建并且成员变量全部注入后执行。

   ```java
   
   /**
    * @author: rolyfish
    * @Description  缓存预热
    */
   @Component
   public class RedisHandler implements InitializingBean {
   
       @Autowired
       StringRedisTemplate stringRedisTemplate;
   
       @Autowired
       IItemService itemService;
   
       @Autowired
       IItemStockService iItemStockService;
   
       private final ThreadPoolExecutor threadpoolexecutor = new ThreadPoolExecutor(10, 15, 60, TimeUnit.SECONDS, new ArrayBlockingQueue<>(100), new ThreadFactory() {
           @Override
           public Thread newThread(Runnable r) {
               return new Thread(r);
           }
       });
   
       private final String ITEM_KEY = "item:id:";
       private final String ITEM_STOCK__KEY = "item:stock:id:";
   
       @Override
       public void afterPropertiesSet() {
           final List<Item> itemList = itemService.list();
           final List<ItemStock> itemStockList = iItemStockService.list();
           threadpoolexecutor.execute(() -> {
               for (Item item : itemList) {
                   stringRedisTemplate.opsForValue().set(ITEM_KEY + item.getId(), JSONUtil.toJsonStr(item));
               }
           });
           threadpoolexecutor.execute(() -> {
               for (ItemStock itemStock : itemStockList) {
                   stringRedisTemplate.opsForValue().set(ITEM_STOCK__KEY + itemStock.getId(), JSONUtil.toJsonStr(itemStock));
               }
           });
       }
   }
   ```

4. 测试

   > 启动后查看。

   ![image-20230421213648506](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230421213648506.png)



##### Openrestry查询Redis

> 在Openresty和Tomcat之间加一个Redis,Openrestry优先查询Redis缓存,缓存未命中再查询Tomcat。

![image-20210821113340111](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20210821113340111.png)



###### 封装redis工具

> Openresty提供了操作Redis的模块,只需要引入对应模块就可以操作Redis。
>
> 将Redis操作封装成工具放在common.lua中。

1. 引入Redis操作模块

   ```lua
   -- require redis
   local redis = require("resty.redis")
   -- init redis
   local red = redis:new();
   red:set_timeouts(1000,1000,1000)
   ```

2. 释放redis连接,放入连接池

   [set_keepalive用法](https://github.com/openresty/lua-resty-redis#set_keepalive)

   ```lua
   local function close_redis(red)
           local pool_max_idle_time = 10000 -- 最大空闲时间,设置大了也没问题
           local pool_size = 100-- 每个nginx工作进程中线程池的大小,设置为并发量/工作进程数。工作进程数的配置在nginx.conf中
           local ok, err = red:set_keepalive(pool_max_idel_time, pool_size)
           -- 成功返回1，失败返回nil
       	if not ok then
                   ngx.log(ngx.ERR, "close conn fail:", err)
           end
   end
   ```

3. 封装查询redis函数

   > 此方法也同样放在common.lua中

   [查询redis方法](https://github.com/openresty/lua-resty-redis#methods)方法名称和redis命令是一致的

   ```lua
   local function read_redis(ip, port, key, pass)
           -- get redis conn
           local ok, err = red:connect(ip,port)
           if not ok then
                   ngx.log(ngx.ERR, "connect err", err)
                   return nil
           end
           local okpass,errpass = red:auth(pass)
                   if not okpass then
                   ngx.log(ngx.ERR, "connect err", errpass)
                   return nil
           end
           -- search redis
           local resp, err = red:get(key)
           if not resp then
                   ngx.log(ngx.ERR, "request err", err, "key = ", key)
           end
           if resp == ngx.null then
                   resp = nil
                   ngx.log(ngx.ERR, "response is null ", "key = ", key)
           end
           close_redis(red)
           return resp
   end
   -- 将方法导出
   local _M = {
       read_http = read_http,
       read_redis = read_redis
   }
   return _M
   ```

   

###### 实现查询redis

> 首先根据商品id查询redis,查询redis失败再去查询Tomcat。

1. 添加一个查询函数

   ```lua
   -- 从 common中获取read_http这个函数
   local read_http = common.read_http
   
   local read_redis = common.read_redis
   
   function read_data(key,path,params)
           local val = read_redis("10.211.55.4", 6379, key, "123123")
           if not val then
                   ngx.log(ngx.ERR, "err  key:", key )
   
                   val = read_http(path,params)
           end
           return val
   end
   ```

2. 查询商品和库存

   ```lua
   -- 获取路径参数
   local id = ngx.var[1]
   -- 根据id查询商品
   local itemJSON = read_data("item:id:" .. id, "/item/".. id, nil)
   -- 根据id查询商品库存
   local itemStockJSON = read_data("item:stock:id:" .. id,"/item/stock/".. id, nil)
   ```

3. 测试



##### Nginx本地缓存

> OpenResty为Nginx提供了**shard dict**的功能，可以在nginx的多个worker之间共享数据，实现缓存功能。

[官网页面](https://github.com/openresty/lua-nginx-module#lua_shared_dict)

语法:`lua_shared_dict <name> <size>`

nginx.conf块：配在http块中

1. 开启缓存

   ```lua
   http {
       ...
       # 开启缓存  名称为item_shared 容量为150m
       luc_shared_dict item_shared  150m;
   	...
   }
   ```

2. 放入缓存数据并设置超时时间

   ```lua
   -- 引入缓存
   local item_share = ngx.shared.item_share
   function read_data(key,expire,path,params)
           -- 查询nginx缓存
           local val = item_share:get(key)
           if not val then
                   ngx.log(ngx.ERR, 'search local share fail key:',key)
   				-- nginx本地缓存未命中,查询redis
                   val = read_redis("10.211.55.4", 6380, key, "123123")
                   if not val then
   						-- redis缓存未命中,查询tomcat
                           ngx.log(ngx.ERR, "[redis fail]err  key:", key )
                           val = read_http(path,params)
                   end
           end
           -- 保存nginx本地缓存
           item_share:set(key,val,expire)
           return val
   end
   ```

## 缓存同步

所以我们必须保证数据库数据、缓存数据的一致性，这就是缓存与数据库的同步。



### 数据同步策略

**设置有效期**：给缓存设置有效期，到期后自动删除。再次查询时更新

- 优势：简单、方便
- 缺点：时效性差，缓存过期之前可能不一致
- 场景：更新频率较低，时效性要求低的业务

**同步双写**：在修改数据库的同时，直接修改缓存

- 优势：时效性强，缓存与数据库强一致
- 缺点：有代码侵入，耦合度高；
- 场景：对一致性、时效性要求较高的缓存数据

**异步通知：**修改数据库时发送事件通知，相关服务监听到通知后修改缓存数据

- 优势：低耦合，可以同时通知多个缓存服务
- 缺点：时效性一般，可能存在中间不一致状态
- 场景：时效性要求一般，有多个服务需要同步



### 基于Canal实现数据同步



#### 安装Canal



##### 基础

> **canal [kə'næl]**，译意为水道/管道/沟渠，主要用途是基于 MySQL 数据库增量日志解析，提供增量数据订阅和消费
>
> 早期阿里巴巴因为杭州和美国双机房部署，存在跨机房同步的业务需求，实现方式主要是基于业务 trigger 获取增量变更。从 2010 年开始，业务逐步尝试数据库日志解析获取增量变更进行同步，由此衍生出了大量的数据库增量订阅和消费业务。
>
> [Githup地址](https://github.com/alibaba/canal)

Canal是基于Mysql主从同步实现的，Mysql主从同步原理：

![img](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/687474703a2f2f646c2e69746579652e636f6d2f75706c6f61642f6174746163686d656e742f303038302f333038362f34363863316131342d653761642d333239302d396433642d3434616335303161373232372e6a7067.jpeg)

- MySQL master 将数据变更写入二进制日志( binary log, 其中记录叫做二进制日志事件binary log events，可以通过 show binlog events 进行查看)
- MySQL slave 将 master 的 binary log events 拷贝到它的中继日志(relay log)
- MySQL slave 重放 relay log 中事件，将数据变更反映它自己的数据



而Canal就是把自己伪装成MySQL的一个slave节点，从而监听master的binary log变化。再把得到的变化信息通知给Canal的客户端，进而完成对其它数据库的同步。canal 工作原理

- canal 模拟 MySQL slave 的交互协议，伪装自己为 MySQL slave ，向 MySQL master 发送dump 协议
- MySQL master 收到 dump 请求，开始推送 binary log 给 slave (即 canal )
- canal 解析 binary log 对象(原始为 byte 流)



##### 安装

###### mysq开启主从

>Canal是基于MySQL的主从同步功能，因此必须先开启MySQL的主从功能才可以。这里以之前用Docker运行的mysql为例：

[quickStart](https://github.com/alibaba/canal/wiki/QuickStart/cfa52f48e2eb49ce1f483c888a54248b99d2cd0a)

1. 开启binlog

   > 修改挂载的配置文件

   ```shell
   vim my.cnf
   ## 添加如下配置
   # 设置binary log文件的存放地址和文件名，叫做mysql-bin
   log-bin=/var/lib/mysql/mysql-bin
   # 指定对哪个database记录binary log events，这里记录item这个库
   binlog-do-db=item
   ```

2. 设置权限账户

   > 处于安全考虑,提供一个用于数据同步的账户。

   [Mysql官方文档](https://dev.mysql.com/doc/refman/8.0/en/grant.html):根据自己的Mysql版本配置

   ```sql
   create user canal@'%' IDENTIFIED by 'canal';
   GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT,SUPER ON *.* TO 'canal'@'%' ; -- identified by 'canal'
   FLUSH PRIVILEGES;
   ```

3. 重启

   ```shell
   docker container restart mysql
   ```

4. 测试

   ```shell
   show master status
   ```

   在conf文件夹下多出如下文件

   ![image-20230422111821982](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230422111821982.png)

   ![image-20230422111702806](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230422111702806.png)

​	

###### 安装Canal

> <svg t="1682243740896" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="880" width="20" height="20"><path d="M631.044 770.398h-440.29c25.096-53.226 58.898-134.887 58.898-189.181v-192.37c0-137.37 117.064-248.997 260.955-248.997 143.882 0 260.952 111.661 260.952 248.963v189.603c0 55.027 34.065 138.142 59.201 191.982H631.044zM510.606 885.349c-29.586 0-55.185-15.516-69.13-38.315h138.253c-13.945 22.8-39.544 38.316-69.123 38.316z m414.497-97.06l2.684-1.303c-21.155-39.66-75.954-154.427-75.954-208.571V388.81c0-179.529-153.081-325.598-341.227-325.598-188.154 0-341.235 146.07-341.235 325.598v192.405c0 47.32-46.517 151.203-75.836 205.58l2.685 1.339a36.22 36.22 0 0 0-7.127 20.575c0 21.157 18.008 38.323 40.157 38.323h226.468c17.974 65.91 80.315 114.958 154.889 114.958 74.566 0 136.913-49.049 154.882-114.958h226.467c22.19 0 40.158-17.165 40.158-38.322a36.378 36.378 0 0 0-7.01-20.423z m0 0" p-id="881"></path></svg>
>
> 这里因为启动canal,一致不成功,可能和自己的Mac M1 或者 虚拟机有关。
>
> 但是发现使用Mac的docker可以使用`Use Rosetta for x86/amd64 emulation on Apple Silicon`设置,来启动,后面自己试了确实可以。以下就是步骤,最后面有同步结果：

1. 创建网络

   ```shell
   docker network create item
   
   ## 网络
   root@ubuntu-linux-22-04-desktop:/home/tmp/docker/mysql/data# docker network ls
   NETWORK ID     NAME      DRIVER    SCOPE
   9578e33a3291   bridge    bridge    local
   9f67845c01d3   host      host      local
   a962aa7631ee   item      bridge    local
   25bcec23a41d   none      null      local
   ```

2. mysql加入此网络

   ```shell
   docker network connect item mysql
   ```

3. 启动canal

   --platform linux/amd64 \

   ```shell
   docker run -p 11111:11111 --name canal \
   -e canal.destinations=item \
   -e canal.instance.master.address=mysql:3306  \
   -e canal.instance.dbUsername=canal  \
   -e canal.instance.dbPassword=canal  \
   -e canal.instance.connectionCharset=UTF-8 \
   -e canal.instance.tsdb.enable=truae \
   -e canal.instance.gtidon=false  \
   -e canal.instance.filter.regex=item\\..* \
   --network item \
   -d canal/canal-server:v1.1.5
   ```

   说明:

   - `-p 11111:11111`：这是canal的默认监听端口
   - `-e canal.instance.master.address=mysql:3306`：数据库地址和端口，如果不知道mysql容器地址，可以通过`docker inspect 容器id`来查看
   - `-e canal.instance.dbUsername=canal`：数据库用户名
   - `-e canal.instance.dbPassword=canal` ：数据库密码
   - `-e canal.instance.filter.regex=`：要监听的表名称

##### 监听canal

> canal提供了各种语言的客户端,当Canal监听到binlog变化时，会通知Canal的客户端

[java客户端](https://github.com/alibaba/canal/wiki/ClientExample)

不过这里我们会使用GitHub上的第三方开源的[canal-starter](https://github.com/NormanGyllenhaal/canal-client)客户端。

与SpringBoot完美整合，自动装配，比官方客户端要简单好用很多。

1. 引入依赖

   [依赖地址](https://mvnrepository.com/artifact/top.javatool/canal-spring-boot-starter)

   ```xml
   <!-- https://mvnrepository.com/artifact/top.javatool/canal-spring-boot-starter -->
   <dependency>
       <groupId>top.javatool</groupId>
       <artifactId>canal-spring-boot-starter</artifactId>
       <version>1.2.1-RELEASE</version>
   </dependency>
   ```

2. 配置

   ```yml
   canal:
     destination: item # canal的集群名字，要与安装canal时设置的名称一致
     server: 10.211.55.5:11111 # canal服务地址
   ```

3. 编写监听器

   通过实现`EntryHandler<T>`接口编写监听器，监听Canal消息。注意两点：

   - 实现类通过`@CanalTable("tb_item")`指定监听的表信息
   - EntryHandler的泛型是与表对应的实体类

#### 测试结果

> 此测试结果是通过  Mac的docker客户端实现的。

![image-20230423194408634](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230423194408634.png)

## 总结

> 三级缓存架构：

![image-20230423194917573](https://xiaochuang6.oss-cn-shanghai.aliyuncs.com/nosql/redis/redis_multi_cache/image-20230423194917573.png)

> 查询请求流程：

- 用户在浏览器数据url：`/item/10001`

- nginx(静态资源提供)

  - 提供静态资源
  - 通过哈希算法,将请求负载均衡到Openrestry(nginx业务服务器)

- Openrestry(nginx业务服务器)

  - 缓存热点数据 (lua_shared_dict)

    - 缓存存在,直接返回数据
    - 缓存不存在,先请求redis,redis数据不存在,再请求tomcat

  - 访问tomcat集群

    通过哈希算法,将请求负载均衡到tomcat

- nginx和redis缓存都未命中,请求tomcat,查询数据库

> 数据同步策略：

对于查询并发要求较高,时效性不强的数据可以放在Openrestry缓存中

因为Openrestry使用的是过期淘汰策略

redis和数据库的一致性如何保证：

使用canal实现:

- canal底层原理是Mysql主从同步,Mysql的主从同步是基于master的bin log,master会将bing log发送给从节点,从节点更具master发过来的binlog进行数据同步
- 使用[canal-starter](https://github.com/NormanGyllenhaal/canal-client)监听Canal,实现EntryHandler接口。当数据更新时更新Jvm和redis缓存







